{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data can be found on https://www.kaggle.com/uciml/breast-cancer-wisconsin-data which has a compilation of data to predict \n",
    "# whether breast cancer is malignant or benign. To compare, I will use \"Breast Cancer Analysis and Prediction\" which was \n",
    "# who used two logistic regression models to create an ensemle with an accuracy of 97.1% (Lugat, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "817ac1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5698ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/Tara/Documents/A_GCU/DSC-540/cancer.csv\")\n",
    "\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d12d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# See if there are any missing values in the data:\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d032dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded variables\n",
    "data = data.drop(['Unnamed: 32','id'], axis = 1)\n",
    "\n",
    "# Assign target variable\n",
    "data.diagnosis.replace(to_replace = dict(M = 1, B = 0), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85c7ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\n",
    "y = np.array(data.diagnosis.tolist())\n",
    "data = data.drop('diagnosis', 1)\n",
    "X = np.array(data)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c017ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Implement a 10-fold cross-validation for a decision tree classifier with 100 trees.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "\n",
    "#  Now use this model to create a bagging based Ensemble\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees)\n",
    "results = model_selection.cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "# We can see that we have an accuracy of 96.67%. Let's see if we can make it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71b79019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736215538847116\n"
     ]
    }
   ],
   "source": [
    "# Now lets try a voting based ensemble which involves logistic regression, decision tree, and support vector machine:\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "\n",
    "# create the models for the ensemble:\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model:\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "# We can see that we have an accuracy of 97.3% which is even higher than our comparison article!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed4903c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whereas Lugat used two logistic regression models to create their ensemble, I first implemented a decision tree \n",
    "# with bagging ensemble which resulted in a 96.6% accuracy. However, when I implemented a logistic regression, decison tree \n",
    "# classifier and support vector machine, I found an accuracy of 97.4%, which prevails Lugat's ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f98b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources:\n",
    "\n",
    "# Brownlee, J. (2016, June 3). Ensemble Machine Learning Algorithms in Python with scikit-learn. \n",
    "# Machine Learning Mastery. https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "# Lugat, V. (2018). Breast Cancer Analysis and Prediction. Kaggle.\n",
    "# https://www.kaggle.com/vincentlugat/breast-cancer-analysis-and-prediction\n",
    "\n",
    "# Paul, S. (2018, Sept 6). Ensemble Learning in Python.\n",
    "# https://www.datacamp.com/community/tutorials/ensemble-learning-python \n",
    "\n",
    "# Samanta, S. (2021). Breast_cancer. Kaggle.\n",
    "# https://www.kaggle.com/sudipsamanta35/breast-cancer \n",
    "\n",
    "# Singh, R.K. (2021). Breast Cancer- Classification. Kaggle.\n",
    "# https://www.kaggle.com/sudipsamanta35/breast-cancer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
